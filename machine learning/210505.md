# Natural Language Processing Ⅱ - Sentiment Analysis

## Ⅰ. Introduction

> - 자연어 처리 감정 분석
> - 나이브 베이즈 기반 감정 예측 및 분석
> - 기타 감정 분석 기법

## Ⅱ. 감정 기반의 텍스트 데이터

### 1. 의의

뉴스, 위키 등의 텍스트가 객관적인 정보를 제공하는 것에 비해 리뷰, 댓글 등의 텍스트는 작성자의 주관적인 평가나 감정을 표현한다. 감정 분석은 비슷한 감정을 표현하는 문장은 `유사한 단어 구성과 언어적 특징`을 보일 것을 전제로, 대량의 텍스트 내에서 표현되는 감정 및 평가를 식별하는 자연어 처리의 한 분야이다.

텍스트 내의 감정을 분류하거나 긍정/부정의 정도를 점수화할 수 있다. 머신러닝 기반 감정 분석 서비스의 경우, 데이터를 통한 모델 학습에서 시작할 수 있다. 학습된 모델에서 새롭게 접하는 텍스트의 감정을 예측할 수 있다.

## Ⅲ. Naive Bayes Classification

### 1. 의의

나이브 베이즈 기반 감정 분석은 조건부 확률과 베이즈 정리를 활용하여 텍스트의 감정 발생 확률을 추정한다. 즉 주어진 텍스트가 특정 감정을 나타낼 확률을 예측하는 것이다. 감정의 발생 확률과 텍스트를 구성하는 단어들의 `가능도(likelihood)`로 텍스트의 감정을 예측한다. 감정의 발생확률은 주어진 텍스트 데이터 내 해당 감정을 표현하는 전체 문서(문장)의 비율로 추정한다.

### 2. 스무딩 & 로그 확률

모델 학습 단계에서 학습 데이터 내에 존재하지 않는 단어에 대해서 감정 발생 확률은 0에 해당하게 된다. 해당 단어에 대한 빈도수(0)를 보정하는 것을 스무딩이라 한다.

또한 문장 내의 단어별 확률을 계속 곱해나가면 결과값은 끊임없이 감소하게 되는데, 이에 각 단어별 로그 확률값의 합으로 결과값을 보정할 수 있다.

### 3. 구현(scikit-learn)

```python
import pandas as pd
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer

raw_text = pd.read_csv("emotions_train.txt", delimiter=';', header=None, names=['sentence','emotion'])
train_data = raw_text['sentence']
train_emotion = raw_text['emotion']

# CountVectorizer 객체인 변수 cv를 만들고, fit_transform 메소드로 train_data를 변환
cv = CountVectorizer()
transformed_text = cv.fit_transform(train_data)

# MultinomialNB 객체인 변수 clf를 만들고, fit 메소드로 2번에서 변환된 train_data와 train_emotion을 학습
clf = MultinomialNB()
clf.fit(transformed_text, train_emotion)

# 문장의 감정을 예측
test_data = ['i am curious', 'i feel gloomy and tired', 'i feel more creative', 'i feel a little mellow today']
doc_vector = cv.transform(test_data)
test_result = clf.predict(doc_vector)
print(test_result)
```

## Ⅳ. 기타 감정 분석 기법

### 1. 임베딩 벡터

### 2. CNN

### 3. RNN

```
출처: [엘리스 AI 트랙 1기](https://aitrack.elice.io/)
```
